{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bemxio/colab-notebooks/blob/main/WhisperDemo/WhisperDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCBbRn9Xm2hA"
      },
      "source": [
        "# Whisper (YT-DLP variant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urEx82SUm_oE"
      },
      "source": [
        "Whisper is a general-purpose speech recognition model, made by OpenAI. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.\n",
        "\n",
        "And this is a Google Colab demo made for it, for fun."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GG1saQRmhOL"
      },
      "source": [
        "#### Install required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0w5O3P-m03u",
        "outputId": "587e2904-0425-4544-bc95-5e1b7c089897"
      },
      "outputs": [],
      "source": [
        "!pip install openai-whisper yt-dlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4OxH_g0n6Lf"
      },
      "source": [
        "#### Set parameters for Whisper and upload the audio file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "Aq0xxdUyo3oW",
        "outputId": "eae2372d-0c92-4d73-eaf7-83c3ea518ff6"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "from moviepy.editor import ipython_display\n",
        "from google.colab import files\n",
        "\n",
        "# constants set by the user in the notebook\n",
        "SOURCE_URL = \"\" # @param {type: \"string\"}\n",
        "\n",
        "MODEL = \"large\" # @param [\"tiny.en\", \"tiny\", \"base.en\", \"base\", \"small.en\", \"small\", \"medium.en\", \"medium\", \"large-v1\", \"large-v2\", \"large\"]\n",
        "LANGUAGE = \"English\" # @param [\"Afrikaans\", \"Albanian\", \"Amharic\", \"Arabic\", \"Armenian\", \"Assamese\", \"Azerbaijani\", \"Bashkir\", \"Basque\", \"Belarusian\", \"Bengali\", \"Bosnian\", \"Breton\", \"Bulgarian\", \"Burmese\", \"Castilian\", \"Catalan\", \"Chinese\", \"Croatian\", \"Czech\", \"Danish\", \"Dutch\", \"English\", \"Estonian\", \"Faroese\", \"Finnish\", \"Flemish\", \"French\", \"Galician\", \"Georgian\", \"German\", \"Greek\", \"Gujarati\", \"Haitian\", \"Haitian Creole\", \"Hausa\", \"Hawaiian\", \"Hebrew\", \"Hindi\", \"Hungarian\", \"Icelandic\", \"Indonesian\", \"Italian\", \"Japanese\", \"Javanese\", \"Kannada\", \"Kazakh\", \"Khmer\", \"Korean\", \"Lao\", \"Latin\", \"Latvian\", \"Letzeburgesch\", \"Lingala\", \"Lithuanian\", \"Luxembourgish\", \"Macedonian\", \"Malagasy\", \"Malay\", \"Malayalam\", \"Maltese\", \"Maori\", \"Marathi\", \"Moldavian\", \"Moldovan\", \"Mongolian\", \"Myanmar\", \"Nepali\", \"Norwegian\", \"Nynorsk\", \"Occitan\", \"Panjabi\", \"Pashto\", \"Persian\", \"Polish\", \"Portuguese\", \"Punjabi\", \"Pushto\", \"Romanian\", \"Russian\", \"Sanskrit\", \"Serbian\", \"Shona\", \"Sindhi\", \"Sinhala\", \"Sinhalese\", \"Slovak\", \"Slovenian\", \"Somali\", \"Spanish\", \"Sundanese\", \"Swahili\", \"Swedish\", \"Tagalog\", \"Tajik\", \"Tamil\", \"Tatar\", \"Telugu\", \"Thai\", \"Tibetan\", \"Turkish\", \"Turkmen\", \"Ukrainian\", \"Urdu\", \"Uzbek\", \"Valencian\", \"Vietnamese\", \"Welsh\", \"Yiddish\", \"Yoruba\"]\n",
        "TASK = \"transcribe\" # @param [\"transcribe\", \"translate\"]\n",
        "\n",
        "# download the video\n",
        "!python3 -m yt_dlp --no-simulate --print-to-file \"%(id)s.%(ext)s\" filename.txt \"{SOURCE_URL}\" --output \"%(id)s.%(ext)s\"\n",
        "\n",
        "# get the path of the video\n",
        "with open(\"filename.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    path = pathlib.Path(file.read().strip())\n",
        "\n",
        "# delete the filename file\n",
        "!rm filename.txt\n",
        "\n",
        "# show a preview of the audio\n",
        "ipython_display(str(path), filetype=\"audio\", maxduration=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMyU_35MwOjB"
      },
      "source": [
        "#### Process the audio file with Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEW9ofqGweRG",
        "outputId": "d5459971-480f-4e3a-84b2-e7f0c871e128"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from whisper.transcribe import transcribe\n",
        "from whisper.utils import get_writer\n",
        "from whisper import load_model\n",
        "\n",
        "# other constants, if you really want to, you can edit them within the code\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "TEMPERATURE = 0.0\n",
        "BEAM_SIZE = 5\n",
        "\n",
        "OUTPUT_FORMAT = \"all\"\n",
        "\n",
        "# load the model for audio processing and the writer for various formats\n",
        "model = load_model(MODEL, device=DEVICE, download_root=None)\n",
        "writer = get_writer(OUTPUT_FORMAT, output_dir=\".\")\n",
        "\n",
        "# get the transcription\n",
        "result = transcribe(\n",
        "    model=model, \n",
        "    audio=str(path), \n",
        "    \n",
        "    verbose=True,\n",
        "\n",
        "    task=TASK,\n",
        "    language=LANGUAGE,\n",
        "\n",
        "    temperature=TEMPERATURE,\n",
        "    beam_size=BEAM_SIZE\n",
        ")\n",
        "\n",
        "# write the result in the defined output format\n",
        "writer(result, str(path), options={})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-yHzG0Fx6J7"
      },
      "source": [
        "You can now access all of the files Whisper generated in the Files tab (that little folder on the left bar).\n",
        "\n",
        "Congratulations! Download stuff you need or generate more stuff if you want."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPUl4hlWHvkn5GZusdDL9rr",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
