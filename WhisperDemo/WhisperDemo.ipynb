{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bemxio/colab-notebooks/blob/main/WhisperDemo/WhisperDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCBbRn9Xm2hA"
      },
      "source": [
        "# Whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urEx82SUm_oE"
      },
      "source": [
        "Whisper is a general-purpose speech recognition model, made by OpenAI. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.\n",
        "\n",
        "And this is a Google Colab demo made for it, for fun."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GG1saQRmhOL"
      },
      "source": [
        "#### Install required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0w5O3P-m03u",
        "outputId": "587e2904-0425-4544-bc95-5e1b7c089897"
      },
      "outputs": [],
      "source": [
        "!pip install openai-whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4OxH_g0n6Lf"
      },
      "source": [
        "#### Set parameters for Whisper and upload the audio file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "Aq0xxdUyo3oW",
        "outputId": "eae2372d-0c92-4d73-eaf7-83c3ea518ff6"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "from moviepy.editor import ipython_display\n",
        "from google.colab import files\n",
        "\n",
        "# constants set by the user in the notebook\n",
        "MODEL = \"large\" # @param [\"tiny.en\", \"tiny\", \"base.en\", \"base\", \"small.en\", \"small\", \"medium.en\", \"medium\", \"large-v1\", \"large-v2\", \"large\"]\n",
        "LANGUAGE = \"English\" # @param [\"Afrikaans\", \"Albanian\", \"Amharic\", \"Arabic\", \"Armenian\", \"Assamese\", \"Azerbaijani\", \"Bashkir\", \"Basque\", \"Belarusian\", \"Bengali\", \"Bosnian\", \"Breton\", \"Bulgarian\", \"Burmese\", \"Castilian\", \"Catalan\", \"Chinese\", \"Croatian\", \"Czech\", \"Danish\", \"Dutch\", \"English\", \"Estonian\", \"Faroese\", \"Finnish\", \"Flemish\", \"French\", \"Galician\", \"Georgian\", \"German\", \"Greek\", \"Gujarati\", \"Haitian\", \"Haitian Creole\", \"Hausa\", \"Hawaiian\", \"Hebrew\", \"Hindi\", \"Hungarian\", \"Icelandic\", \"Indonesian\", \"Italian\", \"Japanese\", \"Javanese\", \"Kannada\", \"Kazakh\", \"Khmer\", \"Korean\", \"Lao\", \"Latin\", \"Latvian\", \"Letzeburgesch\", \"Lingala\", \"Lithuanian\", \"Luxembourgish\", \"Macedonian\", \"Malagasy\", \"Malay\", \"Malayalam\", \"Maltese\", \"Maori\", \"Marathi\", \"Moldavian\", \"Moldovan\", \"Mongolian\", \"Myanmar\", \"Nepali\", \"Norwegian\", \"Nynorsk\", \"Occitan\", \"Panjabi\", \"Pashto\", \"Persian\", \"Polish\", \"Portuguese\", \"Punjabi\", \"Pushto\", \"Romanian\", \"Russian\", \"Sanskrit\", \"Serbian\", \"Shona\", \"Sindhi\", \"Sinhala\", \"Sinhalese\", \"Slovak\", \"Slovenian\", \"Somali\", \"Spanish\", \"Sundanese\", \"Swahili\", \"Swedish\", \"Tagalog\", \"Tajik\", \"Tamil\", \"Tatar\", \"Telugu\", \"Thai\", \"Tibetan\", \"Turkish\", \"Turkmen\", \"Ukrainian\", \"Urdu\", \"Uzbek\", \"Valencian\", \"Vietnamese\", \"Welsh\", \"Yiddish\", \"Yoruba\"]\n",
        "TASK = \"transcribe\" # @param [\"transcribe\", \"translate\"]\n",
        "\n",
        "# show a prompt for file upload\n",
        "uploads = files.upload()\n",
        "\n",
        "# get the path of the file\n",
        "path = pathlib.Path(next(iter(uploads)))\n",
        "\n",
        "# show a preview of the audio\n",
        "ipython_display(str(path), filetype=\"audio\", maxduration=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMyU_35MwOjB"
      },
      "source": [
        "#### Process the audio file with Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEW9ofqGweRG",
        "outputId": "d5459971-480f-4e3a-84b2-e7f0c871e128"
      },
      "outputs": [],
      "source": [
        "!python -m whisper {path} --model {MODEL} --language {LANGUAGE} --task {TASK}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-yHzG0Fx6J7"
      },
      "source": [
        "You can now access all of the files Whisper generated in the Files tab (that little folder on the left bar).\n",
        "\n",
        "Congratulations! Download stuff you need or generate more stuff if you want."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPUl4hlWHvkn5GZusdDL9rr",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
