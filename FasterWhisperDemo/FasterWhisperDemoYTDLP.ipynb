{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bemxio/colab-notebooks/blob/main/FasterWhisperDemo/FasterWhisperDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCBbRn9Xm2hA"
      },
      "source": [
        "# Faster Whisper (YT-DLP variant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urEx82SUm_oE"
      },
      "source": [
        "Faster Whisper is a reimplementation of OpenAI's Whisper model using CTranslate2, which is a fast inference engine for Transformer models.\n",
        "\n",
        "This implementation is up to 4 times faster than OpenAI's Whisper for the same accuracy while using less memory. The efficiency can be further improved with 8-bit quantization on both CPU and GPU.\n",
        "\n",
        "And this is a Google Colab demo made for it, for fun."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GG1saQRmhOL"
      },
      "source": [
        "#### Install required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0w5O3P-m03u",
        "outputId": "587e2904-0425-4544-bc95-5e1b7c089897"
      },
      "outputs": [],
      "source": [
        "%pip install faster-whisper srt yt-dlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4OxH_g0n6Lf"
      },
      "source": [
        "#### Set parameters for Faster Whisper and upload the audio file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "Aq0xxdUyo3oW",
        "outputId": "eae2372d-0c92-4d73-eaf7-83c3ea518ff6"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "from moviepy.editor import ipython_display\n",
        "from google.colab import files\n",
        "\n",
        "# constants set by the user in the notebook\n",
        "SOURCE_URL = \"\" # @param {type: \"string\"}\n",
        "\n",
        "MODEL = \"large-v3\" # @param [\"tiny.en\", \"tiny\", \"base.en\", \"base\", \"small.en\", \"small\", \"medium.en\", \"medium\", \"large-v1\", \"large-v2\", \"large-v3\", \"distil-large-v2\", \"distil-medium.en\", \"distil-small.en\", \"distil-large-v3\", \"large-v3-turbo\"]\n",
        "LANGUAGE = \"en\" # @param [\"af\", \"am\", \"ar\", \"as\", \"az\", \"ba\", \"be\", \"bg\", \"bn\", \"bo\", \"br\", \"bs\", \"ca\", \"cs\", \"cy\", \"da\", \"de\", \"el\", \"en\", \"es\", \"et\", \"eu\", \"fa\", \"fi\", \"fo\", \"fr\", \"gl\", \"gu\", \"ha\", \"haw\", \"he\", \"hi\", \"hr\", \"ht\", \"hu\", \"hy\", \"id\", \"is\", \"it\", \"ja\", \"jw\", \"ka\", \"kk\", \"km\", \"kn\", \"ko\", \"la\", \"lb\", \"ln\", \"lo\", \"lt\", \"lv\", \"mg\", \"mi\", \"mk\", \"ml\", \"mn\", \"mr\", \"ms\", \"mt\", \"my\", \"ne\", \"nl\", \"nn\", \"no\", \"oc\", \"pa\", \"pl\", \"ps\", \"pt\", \"ro\", \"ru\", \"sa\", \"sd\", \"si\", \"sk\", \"sl\", \"sn\", \"so\", \"sq\", \"sr\", \"su\", \"sv\", \"sw\", \"ta\", \"te\", \"tg\", \"th\", \"tk\", \"tl\", \"tr\", \"tt\", \"uk\", \"ur\", \"uz\", \"vi\", \"yi\", \"yo\", \"zh\", \"yue\"]\n",
        "TASK = \"transcribe\" # @param [\"transcribe\", \"translate\"]\n",
        "\n",
        "# download the video\n",
        "!python3 -m yt_dlp --no-simulate --print-to-file \"%(title)s.%(ext)s\" filename.txt \"{SOURCE_URL}\" --output \"%(title)s.%(ext)s\"\n",
        "\n",
        "# get the path of the video\n",
        "with open(\"filename.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    path = pathlib.Path(file.read().strip())\n",
        "\n",
        "# delete the filename file\n",
        "!rm filename.txt\n",
        "\n",
        "# show a preview of the audio\n",
        "ipython_display(str(path), filetype=\"audio\", maxduration=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMyU_35MwOjB"
      },
      "source": [
        "#### Process the audio file with Faster Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEW9ofqGweRG",
        "outputId": "d5459971-480f-4e3a-84b2-e7f0c871e128"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "from faster_whisper import WhisperModel\n",
        "import srt\n",
        "\n",
        "# initialize neccecary variables\n",
        "model = WhisperModel(MODEL, device=\"cuda\", compute_type=\"float16\")\n",
        "subtitles = []\n",
        "transcription = \"\"\n",
        "\n",
        "# initialize the transcription generator\n",
        "segments, _ = model.transcribe(path, language=LANGUAGE, task=TASK)\n",
        "\n",
        "# transcribe the audio\n",
        "for index, segment in enumerate(segments):\n",
        "    start = timedelta(seconds=segment.start)\n",
        "    end = timedelta(seconds=segment.end)\n",
        "    text = segment.text.strip()\n",
        "\n",
        "    print(f\"[{start} --> {end}] {text}\")\n",
        "\n",
        "    subtitles.append(srt.Subtitle(\n",
        "        index=index + 1,\n",
        "        start=start,\n",
        "        end=end,\n",
        "        content=text\n",
        "    ))\n",
        "    transcription += text + \"\\n\"\n",
        "\n",
        "# save the subtitles and the transcription to seperate files\n",
        "with open(path.with_suffix(\".srt\"), \"w\") as file:\n",
        "    file.write(srt.compose(subtitles))\n",
        "\n",
        "with open(path.with_suffix(\".txt\"), \"w\") as file:\n",
        "    file.write(transcription)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-yHzG0Fx6J7"
      },
      "source": [
        "Congratulations! You can now access all of the files Faster Whisper generated in the Files tab (that little folder on the left bar).\n",
        "\n",
        "Download stuff you need or generate more stuff if you want."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPUl4hlWHvkn5GZusdDL9rr",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
